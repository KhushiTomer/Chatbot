# -*- coding: utf-8 -*-
"""Chatbot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HrZGbe3Odx8Xp0ntEjmannfPOhYky6MJ

# **INTRODUCTION**
THIS CHATBOT IS A BASIC CHATBOT WHICH IS MADE BY THE BASIC KNOWLEDGE OF CHATGPT. THIS CHATBOT IS BASED ON BASIC COOKING INTERVIEWERS QUESTIONS AND ANSWER.

# **DOWNLOADING DATA**
"""

!git clone https://github.com/irina1nik/context_data.git

"""# **INSTALL DEPENDENCIES**"""

!pip install gpt-index
!pip install langchain

"""# **DEFINE THE FUNCTIONS**"""

from gpt_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper
from langchain import OpenAI
import sys
import os
from IPython.display import Markdown, display

def construct_index(directory_path):
  # set maximum input ize
  max_input_size =4096
  #set number of output tokens
  num_outputs =300
  #set maximum chunk overlap
  max_chunk_overlap =20
  #set chunk size limit
  chunk_size_limit =600

  #define LLM
  llm_predictor =LLMPredictor(llm=OpenAI(temperature =0.5, model_name= "text-davinci-003", max_tokens= num_outputs))
  prompt_helper= PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit= chunk_size_limit)
  documents= SimpleDirectoryReader(directory_path).load_data()
  
  index =GPTSimpleVectorIndex(documents, llm_predictor =llm_predictor, prompt_helper =prompt_helper)
  index.save_to_disk('index.json')
  return index

def ask_ai():
  index= GPTSimpleVectorIndex.load_from_disk('index.json')
  while True:
    query= input("What do you want to ask?")
    response= index.query(query,response_mode="Compact")
    display(Markdown(f"Response:<b>{response.response}</b>"))

"""# **SET OpenAI API Key**


"""

os.environ["OpenAI_API_KEY"]= input("Paste your OpenAI API key and hit enter:")

"""# **CONSTRUCT AN INDEX**
Now we are ready to construct index. This will take every file in folder 'data', split into chunks, and embed it with OpenAI's embedding API.

**Be Careful:** Running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment/project.
"""

construct_index("context_data/data")



"""# **ASK QUESTIONS**
It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input. 

If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:
1. Why people cook at home? Make classification
2. Make classification about what frustrates people about cooking?
3. Brainstorm marketing campaign ideas for an air fryer that would appeal people that cook at home
4. Which kitchen appliences people use most often?
5. What people like about cooking at home?
"""

ask_ai()